{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "# 6: Stereo Matching Fundamentals\n",
    "\n",
    "A key problem in computer vision is to estimate the depth of a scene from a pair of stereo images. This is known as stereo matching. In this notebook, we will learn about the fundamentals of stereo matching and implement a simple stereo matching algorithm.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "For this notebook I have used some data from the newest Middlebury Stereo Evaluation dataset. The dataset can be seen here:\n",
    "\n",
    "- [2021 Mobile stereo datasets with ground truth](https://vision.middlebury.edu/stereo/data/scenes2021/)\n",
    "- [Download all as zip](https://vision.middlebury.edu/stereo/data/scenes2021/zip/all.zip)\n",
    "\n",
    "Only the dataset \"traproom1\" is included in this repository. You can download the rest using the zip link above. To make it seamlessly integrate with repo by:\n",
    "\n",
    "- Placing the desired scene folders in the `test_data` folder.\n",
    "- Add the dataset to `TestDataPaths` similar to that of `traproom1`:\n",
    "    ```python\n",
    "    class TestDataPaths:\n",
    "        ...\n",
    "        traproom1_dir: Path = _test_data_dir / \"traproom1\"\n",
    "        your_folder_dir: Path = _test_data_dir / \"your_folder\"\n",
    "    ```\n",
    "\n",
    "### Custom\n",
    "\n",
    "I have also included some data from my own setup that is better suited for us to get started with stereo matching. The data is in the `test_data` folder in `stereo_data_0` and `stereo_data_1` directories, these are read with the same function. These does not have any ground truth data.\n",
    "\n",
    "## Load data\n",
    "\n",
    "Lets start by loading the [traproom1](https://vision.middlebury.edu/stereo/data/scenes2021/data/traproom1/) dataset from the repository `test_data` folder and visualize the stereo images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from nptyping import Float32, NDArray, Shape\n",
    "import numpy as np\n",
    "\n",
    "from oaf_vision_3d._test_data_paths import TestDataPaths\n",
    "from oaf_vision_3d.lens_model import LensModel\n",
    "from oaf_vision_3d.point_cloud_visualization import open3d_visualize_point_cloud\n",
    "from oaf_vision_3d.transformation_matrix import TransformationMatrix\n",
    "from oaf_vision_3d._stereo_data_reader import StereoData\n",
    "\n",
    "data_dir = TestDataPaths.traproom1_dir\n",
    "stereo_data = StereoData.from_path(data_dir)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 12))\n",
    "ax[0].imshow(stereo_data.image_0, cmap=\"gray\", vmin=0, vmax=1)\n",
    "ax[0].set_title(\"Image left\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].imshow(stereo_data.image_1, cmap=\"gray\", vmin=0, vmax=1)\n",
    "ax[1].set_title(\"Image right\")\n",
    "ax[1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data also have ground truth disparity maps that we can use to triangulate the depth of the scene:\n",
    "\n",
    "$$ \\text{disparity} = x_{left} - x_{right} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "if stereo_data.ground_truth_disparity is not None:\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.imshow(stereo_data.ground_truth_disparity)\n",
    "    plt.axis(\"off\")\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Ground truth disparity\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangulate disparity\n",
    "\n",
    "We can very simply triangulate the depth of the scene by using the disparity map and the camera calibration of the system by using the [`triangulate_points`](../oaf_vision_3d/triangulation.py) function that we implemented in the previous [workshop](05_dual_camera_setups.ipynb).\n",
    "\n",
    "To triangulate the depth we need to create two sets of pixel grid, which can be done easily using disparity by using the same $y$-index while calculating the $x$-index for the right image as:\n",
    "\n",
    "$$ x_{right} = x_{left} - \\text{disparity} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from oaf_vision_3d.triangulation import triangulate_points\n",
    "\n",
    "\n",
    "def triangulate_disparity(\n",
    "    disparity: NDArray[Shape[\"H, W\"], Float32],\n",
    "    lens_model_0: LensModel,\n",
    "    lens_model_1: LensModel,\n",
    "    transformation_matrix: TransformationMatrix,\n",
    ") -> NDArray[Shape[\"H, W, 3\"], Float32]:\n",
    "    y, x = np.indices(disparity.shape, dtype=np.float32)\n",
    "    pixels_0 = np.stack([x, y], axis=-1)\n",
    "    pixels_1 = np.stack([x - disparity, y], axis=-1)\n",
    "\n",
    "    undistortied_normalized_pixels_0 = lens_model_0.undistort_pixels(\n",
    "        normalized_pixels=lens_model_0.normalize_pixels(pixels=pixels_0)\n",
    "    )\n",
    "    undistortied_normalized_pixels_1 = lens_model_1.undistort_pixels(\n",
    "        normalized_pixels=lens_model_1.normalize_pixels(pixels=pixels_1)\n",
    "    )\n",
    "\n",
    "    return triangulate_points(\n",
    "        undistorted_normalized_pixels_0=undistortied_normalized_pixels_0,\n",
    "        undistorted_normalized_pixels_1=undistortied_normalized_pixels_1,\n",
    "        transformation_matrix=transformation_matrix,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And since we have the ground truth disparities we can use them to calculate the depth of the scene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "if stereo_data.ground_truth_disparity is not None:\n",
    "    xyz_ground_truth = triangulate_disparity(\n",
    "        disparity=stereo_data.ground_truth_disparity,\n",
    "        lens_model_0=stereo_data.lens_model_0,\n",
    "        lens_model_1=stereo_data.lens_model_1,\n",
    "        transformation_matrix=stereo_data.transformation_matrix,\n",
    "    )\n",
    "\n",
    "    if xyz_ground_truth is not None:\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.imshow(xyz_ground_truth[..., 2])\n",
    "        plt.axis(\"off\")\n",
    "        plt.colorbar()\n",
    "        plt.title(\"Ground truth depth\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open3D Pointcloud\n",
    "\n",
    "I will show of the pointcloud using Open3D, which is a great library for 3D visualization but also hard to work with in interactive mode, especially jupyter book. The pointcloud will open in a separate window, and block the execution of the code. You can close the window to continue the execution of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "if xyz_ground_truth is not None:\n",
    "    open3d_visualize_point_cloud(xyz=xyz_ground_truth, rgb=stereo_data.image_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stereo matching\n",
    "\n",
    "For stereo matching we will implement a simple block matching algorithm, alot of the stereo field has moved to deep learning based methods, I highly recommend looking at the [Middlebury Stereo Evaluation](https://vision.middlebury.edu/stereo/eval/) for more information on the state of the art in stereo matching. Many of these networks/methods are also easily accessible as many share the full source code. \n",
    "\n",
    "### Load data\n",
    "\n",
    "For stereo matching we will use a different dataset that I have included, this has fewer disparities. But feel free to later test your solution with different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "data_dir = TestDataPaths.stereo_data_0_dir\n",
    "stereo_matching_data = StereoData.from_path(data_dir)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 12))\n",
    "ax[0].imshow(stereo_matching_data.image_0, cmap=\"gray\", vmin=0, vmax=1)\n",
    "ax[0].set_title(\"Image left\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].imshow(stereo_matching_data.image_1, cmap=\"gray\", vmin=0, vmax=1)\n",
    "ax[1].set_title(\"Image right\")\n",
    "ax[1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is of a flat planar ish piece of paper with an aruco marker on it. Since the quality is fairly high resolution we actually have alot of detail to work with, but we will struggle in many areas.\n",
    "\n",
    "### Block matching\n",
    "\n",
    "The block matching algorithm is a simple algorithm that works by comparing blocks of pixels in the left image with blocks of pixels in the right image. The algorithm works by sliding a window of a fixed size over the left image and comparing the block in the left image with blocks in the right image. The block with the smallest difference is the best match. We can easily implement this algorithm using numpy by(remember we assume movement in the x-direction):\n",
    "\n",
    "- Defining a disparity range we want to search in.\n",
    "- For each disparity:\n",
    "    - Shift the right image by the disparity.\n",
    "    - Calculate some error between the left and right image (I will use Absolute Difference).\n",
    "    - Sum the error over the block size.\n",
    "  - The disparity with the smallest error is the best match for each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d\n",
    "\n",
    "\n",
    "kernel_size = 29\n",
    "\n",
    "image_0 = stereo_matching_data.image_0\n",
    "image_1 = stereo_matching_data.image_1\n",
    "\n",
    "disparities = np.arange(\n",
    "    stereo_matching_data.expected_disparity[0],\n",
    "    stereo_matching_data.expected_disparity[1] + 1,\n",
    "    dtype=np.int32,\n",
    ")\n",
    "\n",
    "error = []\n",
    "for _disparity in disparities:\n",
    "    shifted_image_1 = np.roll(image_1, _disparity, axis=1)\n",
    "    single_pixel_error = np.abs(image_0 - shifted_image_1).sum(axis=-1)\n",
    "\n",
    "    convoluted_error = convolve2d(\n",
    "        convolve2d(\n",
    "            single_pixel_error, np.ones((1, kernel_size)) / kernel_size, mode=\"same\"\n",
    "        ),\n",
    "        np.ones((kernel_size, 1)) / kernel_size,\n",
    "        mode=\"same\",\n",
    "    )\n",
    "    error.append(convoluted_error)\n",
    "\n",
    "disparity_error = np.array(error, dtype=np.float32)\n",
    "disparity = disparities[np.argmin(disparity_error, axis=0)].astype(np.float32)\n",
    "\n",
    "disparity[:, : int(np.abs(stereo_matching_data.expected_disparity).max())] = np.nan\n",
    "disparity[:, -int(np.abs(stereo_matching_data.expected_disparity).max()) :] = np.nan\n",
    "disparity[disparity >= int(stereo_matching_data.expected_disparity.max())] = np.nan\n",
    "disparity[disparity <= int(stereo_matching_data.expected_disparity.min())] = np.nan\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(disparity)\n",
    "plt.colorbar()\n",
    "plt.title(\"Disparity Map\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "To evaluate the current results let us calculate the depth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "xyz_simple = triangulate_disparity(\n",
    "    disparity=disparity,\n",
    "    lens_model_0=stereo_matching_data.lens_model_0,\n",
    "    lens_model_1=stereo_matching_data.lens_model_1,\n",
    "    transformation_matrix=stereo_matching_data.transformation_matrix,\n",
    ")\n",
    "\n",
    "if xyz_simple is not None:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(xyz_simple[..., 2])\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Depth Map Simple Block Matching\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran this with a 29x29 kernel, which takes some time, but get failry reasonable results on a near flat object like this. In the point cloud below (if set up Open3D above) you can sede the discrete disparity values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "if xyz_simple is not None:\n",
    "    open3d_visualize_point_cloud(xyz=xyz_simple, rgb=stereo_matching_data.image_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subdisparity resolution\n",
    "\n",
    "To avoid having discrete depth levels, we an do a subpixel fit on the disparity values. We can do this easily by not piciking the disparity with the smallest error, but instead fitting a 2nd degree polynomial to the error values for the index $\\pm$ 1 of the smallest error and then finding the minima of the polynomial.\n",
    "\n",
    "To do this effieciently we use $x = [-1, 0, 1]$ and $y = [y_{-1}, y_{0}, y_{1}]$ and fit a 2nd degree polynomial to this:\n",
    "\n",
    "$$ y = ax^2 + bx + c $$\n",
    "\n",
    "Which becomes a matrix system:\n",
    "\n",
    "$$ \\begin{bmatrix} 1 & -1 & 1 \\\\ 0 & 0 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix} \\begin{bmatrix} a \\\\ b \\\\ c \\end{bmatrix} = \\begin{bmatrix} y_{-1} \\\\ y_{0} \\\\ y_{1} \\end{bmatrix} $$\n",
    "\n",
    "That gives the following solution:\n",
    "\n",
    "$$ \\begin{align*} a &= 0.5 (y_{-1} + y_{1}) - y_{0} \\\\ b &= 0.5 (y_{1} - y_{-1}) \\\\ c &= y_{0} \\end{align*} $$\n",
    "\n",
    "The minimum of this polynomial can be found when it's derivative is zero:\n",
    "\n",
    "$$ \\frac{dy}{dx} = 2ax + b = 0 \\\\ \\Downarrow \\\\ x = -\\frac{b}{2a} $$\n",
    "\n",
    "Since we used $x = [-1, 0, 1]$ we can find the subpixel disparity by adding this $x$ (more like a $\\Delta x$) to the idx of the smallest error.\n",
    "\n",
    "$$ \\text{subpixel disparity} = idx + x $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from nptyping import Int32\n",
    "\n",
    "\n",
    "def find_subpixel_disparities_poly_2(\n",
    "    disparities: NDArray[Shape[\"N\"], Int32],\n",
    "    function_value: NDArray[Shape[\"N, H, W\"], Float32],\n",
    ") -> NDArray[Shape[\"H, W\"], Float32]:\n",
    "    h_idx = np.arange(function_value.shape[1])\n",
    "    w_idx = np.arange(function_value.shape[2])\n",
    "    h_idx, w_idx = np.meshgrid(h_idx, w_idx, indexing=\"ij\")\n",
    "\n",
    "    idx = np.clip(np.argmin(function_value, axis=0), 1, disparities.shape[0] - 2)\n",
    "\n",
    "    f_0 = function_value[idx - 1, h_idx, w_idx]\n",
    "    f_1 = function_value[idx, h_idx, w_idx]\n",
    "    f_2 = function_value[idx + 1, h_idx, w_idx]\n",
    "\n",
    "    a = 0.5 * (f_0 + f_2) - f_1\n",
    "    b = 0.5 * (f_2 - f_0)\n",
    "\n",
    "    denom = 2 * a\n",
    "    denom = np.where(denom == 0, np.nan, denom)\n",
    "\n",
    "    delta = -b / denom\n",
    "    delta = np.where(np.abs(delta) > 1, np.nan, delta)\n",
    "\n",
    "    return disparities[idx].astype(np.float32) + delta\n",
    "\n",
    "\n",
    "disparity_sub_pixel = find_subpixel_disparities_poly_2(\n",
    "    disparities=disparities,\n",
    "    function_value=disparity_error,\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(disparity_sub_pixel)\n",
    "plt.colorbar()\n",
    "plt.title(\"Sub Pixel Disparity Map\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "xyz_sub_pixel = triangulate_disparity(\n",
    "    disparity=disparity_sub_pixel,\n",
    "    lens_model_0=stereo_matching_data.lens_model_0,\n",
    "    lens_model_1=stereo_matching_data.lens_model_1,\n",
    "    transformation_matrix=stereo_matching_data.transformation_matrix,\n",
    ")\n",
    "\n",
    "if xyz_sub_pixel is not None:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(xyz_sub_pixel[..., 2])\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Sub Pixel Depth Map\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has removed the discrete disparity levels and given us a subdisparity resolution. We still see some artifacts, but this is a good start. For those with Open3D set up you can see the subpixel disparity in the point cloud below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "if xyz_sub_pixel is not None:\n",
    "    open3d_visualize_point_cloud(xyz=xyz_sub_pixel, rgb=stereo_matching_data.image_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Stereo Matching\n",
    "\n",
    "Until next session I want you to test out how you can improve the stereo matching algorithm. Below is a full implementation that allows you to alter some flags to test different things:\n",
    "\n",
    "- `block_size` - The size of the block to compare, what happens if you adjust this?\n",
    "- `disparity_range` - The range of disparities to search in, what happens if you adjust this?\n",
    "- `subpixel_fit` - If you want to do a subpixel fit or not as we have seen in this workshop.\n",
    "- `cost_function` - What cost function to use, I currenntly used the absolute difference, and utilizing all color channels. Can you test a different cost function?\n",
    "  - You can also try third party libraries like OpenCV that have some built in stereo matching functions (F.Ex. [`cv::stereo::StereoBinaryBM`](https://docs.opencv.org/3.4/dd/d86/group__stereo.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class CostFunction(Enum):\n",
    "    SUM_OF_ABSOLUTE_DIFFERENCE = 0\n",
    "    SUM_OF_SQUARED_DIFFERENCE = 1\n",
    "\n",
    "\n",
    "def _get_cost(\n",
    "    image_0: NDArray[Shape[\"H, W, ...\"], Float32],\n",
    "    image_1: NDArray[Shape[\"H, W, ...\"], Float32],\n",
    "    cost_function: CostFunction,\n",
    ") -> NDArray[Shape[\"H, W\"], Float32]:\n",
    "    match cost_function:\n",
    "        case CostFunction.SUM_OF_ABSOLUTE_DIFFERENCE:\n",
    "            return np.abs(image_0 - image_1).sum(axis=-1)\n",
    "        case CostFunction.SUM_OF_SQUARED_DIFFERENCE:\n",
    "            return ((image_0 - image_1) ** 2).sum(axis=-1)\n",
    "        case _:\n",
    "            raise ValueError(\"Invalid cost function\")\n",
    "\n",
    "\n",
    "def block_matching(\n",
    "    image_0: NDArray[Shape[\"H, W\"], Float32],\n",
    "    image_1: NDArray[Shape[\"H, W\"], Float32],\n",
    "    disparity_range: NDArray[Shape[\"2\"], Float32],\n",
    "    block_size: int,\n",
    "    subpixel_fit: bool,\n",
    "    cost_function: CostFunction,\n",
    ") -> NDArray[Shape[\"H, W\"], Float32]:\n",
    "    disparities = np.arange(disparity_range[0], disparity_range[1], dtype=np.int32)\n",
    "    error = []\n",
    "    for _disparity in disparities:\n",
    "        shifted_image_1 = np.roll(image_1, _disparity, axis=1)\n",
    "        single_pixel_error = _get_cost(image_0, shifted_image_1, cost_function)\n",
    "\n",
    "        convoluted_error = convolve2d(\n",
    "            convolve2d(\n",
    "                single_pixel_error, np.ones((1, block_size)) / block_size, mode=\"same\"\n",
    "            ),\n",
    "            np.ones((block_size, 1)) / block_size,\n",
    "            mode=\"same\",\n",
    "        )\n",
    "        error.append(convoluted_error)\n",
    "\n",
    "    disparity_error = np.array(error, dtype=np.float32)\n",
    "\n",
    "    if subpixel_fit:\n",
    "        disparity = find_subpixel_disparities_poly_2(\n",
    "            disparities=disparities, function_value=disparity_error\n",
    "        )\n",
    "    else:\n",
    "        disparity = disparities[np.argmin(disparity_error, axis=0)].astype(np.float32)\n",
    "\n",
    "    disparity[:, : int(np.abs(disparities).max())] = np.nan\n",
    "    disparity[:, -int(np.abs(disparities).max()) :] = np.nan\n",
    "    disparity[disparity >= disparities.max()] = np.nan\n",
    "    disparity[disparity <= disparities.min()] = np.nan\n",
    "\n",
    "    return disparity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be used to test any wanted dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose testset\n",
    "data_dir = TestDataPaths.stereo_data_0_dir\n",
    "data = StereoData.from_path(data_dir)\n",
    "\n",
    "# Adjustable parameters\n",
    "block_size = 29\n",
    "disparity_range = data.expected_disparity\n",
    "subpixel_fit = True\n",
    "cost_function = CostFunction.SUM_OF_ABSOLUTE_DIFFERENCE\n",
    "\n",
    "# Run block matching\n",
    "disparity_new = block_matching(\n",
    "    image_0=data.image_0,\n",
    "    image_1=data.image_1,\n",
    "    disparity_range=disparity_range,\n",
    "    block_size=block_size,\n",
    "    subpixel_fit=subpixel_fit,\n",
    "    cost_function=cost_function,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(disparity)\n",
    "plt.colorbar()\n",
    "plt.title(\"Disparity Map\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_new = triangulate_disparity(\n",
    "    disparity=disparity_new,\n",
    "    lens_model_0=data.lens_model_0,\n",
    "    lens_model_1=data.lens_model_1,\n",
    "    transformation_matrix=data.transformation_matrix,\n",
    ")\n",
    "\n",
    "if xyz_new is not None:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(xyz_new[..., 2])\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Depth Map\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if xyz_new is not None:\n",
    "    open3d_visualize_point_cloud(xyz=xyz_new, rgb=data.image_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different kernels and cost functions\n",
    "\n",
    "Here we test both the absolute difference and the squared difference cost functions. All are run with a block size of $11 \\times 11$, $17 \\times 17$, $23 \\times 23$ and $29 \\times 29$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose testset\n",
    "data_dir = TestDataPaths.stereo_data_0_dir\n",
    "data = StereoData.from_path(data_dir)\n",
    "\n",
    "# Adjustable parameters\n",
    "block_size = 29\n",
    "disparity_range = data.expected_disparity\n",
    "subpixel_fit = True\n",
    "cost_function = CostFunction.SUM_OF_ABSOLUTE_DIFFERENCE\n",
    "kernels = [11, 17, 23, 29]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(16, 16))\n",
    "for kernel, ax in zip(kernels, axs.ravel()):\n",
    "    disparity_new = block_matching(\n",
    "        image_0=data.image_0,\n",
    "        image_1=data.image_1,\n",
    "        disparity_range=disparity_range,\n",
    "        block_size=kernel,\n",
    "        subpixel_fit=subpixel_fit,\n",
    "        cost_function=cost_function,\n",
    "    )\n",
    "\n",
    "    ax.imshow(disparity_new)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(f\"Disparity Map (Kernel: {kernel})\")\n",
    "fig.tight_layout()\n",
    "fig.suptitle(\"Block Matching with Sum of Absolute Difference\")\n",
    "\n",
    "\n",
    "cost_function = CostFunction.SUM_OF_SQUARED_DIFFERENCE\n",
    "fig, axs = plt.subplots(2, 2, figsize=(16, 16))\n",
    "for kernel, ax in zip(kernels, axs.ravel()):\n",
    "    disparity_new = block_matching(\n",
    "        image_0=data.image_0,\n",
    "        image_1=data.image_1,\n",
    "        disparity_range=disparity_range,\n",
    "        block_size=kernel,\n",
    "        subpixel_fit=subpixel_fit,\n",
    "        cost_function=cost_function,\n",
    "    )\n",
    "\n",
    "    ax.imshow(disparity_new)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(f\"Disparity Map (Kernel: {kernel})\")\n",
    "fig.tight_layout()\n",
    "fig.suptitle(\"Block Matching with Sum of Squared Difference\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
