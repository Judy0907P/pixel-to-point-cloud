{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "# 8: Building Your 3D Vision Pipeline\n",
    "\n",
    "As we now are comming to an end of this series, we have covered a lot of ground. We have learned about the basics of 3D vision, the first half we covered a singel camera; How to model a camera, how to project 3D points into 2D and how to estimate a pose from 2D-3D correspondences. In the second half we covered stereo vision; How to model two cameras compared to each other, how to triangulate 3D points from two 2D points, epipolar geometry and stereo matching.\n",
    "\n",
    "For the final workshop we will try to put the tools we have made into a full 3D stereo matching pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Stereo Matching Pipeline\n",
    "\n",
    "To make a complete pipeline we will combine from all the previous workshops. We start by loading test data, \n",
    "\n",
    ":::{admonition} Dataset\n",
    ":class: tip, dropdown\n",
    "In this workshop we will use the Middlebury Stereo Evaluation dataset. The dataset can be seen here:\n",
    "\n",
    "- [2021 Mobile stereo datasets with ground truth](https://vision.middlebury.edu/stereo/data/scenes2021/)\n",
    "- [Download all as zip](https://vision.middlebury.edu/stereo/data/scenes2021/zip/all.zip)\n",
    "\n",
    "Only the dataset \"traproom1\" is included in this repository. You can download the rest using the zip link above. To make it seamlessly integrate with repo by:\n",
    "\n",
    "- Placing the desired scene folders in the `test_data` folder.\n",
    "- Add the dataset to `TestDataPaths` similar to that of `traproom1`:\n",
    "    ```python\n",
    "    class TestDataPaths:\n",
    "        ...\n",
    "        traproom1_dir: Path = _test_data_dir / \"traproom1\"\n",
    "        your_folder_dir: Path = _test_data_dir / \"your_folder\"\n",
    "    ```\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from oaf_vision_3d._notebook_tools import simple_plot\n",
    "from oaf_vision_3d._test_data_paths import TestDataPaths\n",
    "from oaf_vision_3d.block_matching import block_matching\n",
    "from oaf_vision_3d.plane_sweeping import plane_sweeping\n",
    "from oaf_vision_3d.point_cloud_visualization import open3d_visualize_point_cloud\n",
    "from oaf_vision_3d._stereo_data_reader import StereoData\n",
    "from oaf_vision_3d.triangulation import triangulate_disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "data_dir = TestDataPaths.traproom1_dir\n",
    "stereo_data = StereoData.from_path(data_dir)\n",
    "rgb = stereo_data.image_0\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 12))\n",
    "ax[0].imshow(stereo_data.image_0, cmap=\"gray\", vmin=0, vmax=1)\n",
    "ax[0].set_title(\"Image left\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].imshow(stereo_data.image_1, cmap=\"gray\", vmin=0, vmax=1)\n",
    "ax[1].set_title(\"Image right\")\n",
    "ax[1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block Matching\n",
    "\n",
    "We can perform block matching on the stereo images to get a disparity map using the [`block_matching`](../oaf_vision_3d/block_matching.py) module that we implemented in [workshop 6](./06_stereo_matching_fundamentals.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disparity_map = block_matching(\n",
    "    image_0=stereo_data.image_0,\n",
    "    image_1=stereo_data.image_1,\n",
    "    disparity_range=stereo_data.expected_disparity,\n",
    "    block_size=np.array([11, 11], dtype=np.int32),\n",
    ")\n",
    "simple_plot(data=disparity_map, title=\"Block Matching Disparity Map\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the dispariries we can triangualte a depth map using the triangulation math from [workshop 5](./05_dual_camera_setups.ipynb). The function [`triangulate_disparity`] that we made in [workshop 6](./06_stereo_matching_fundamentals.ipynb) can be used to triangulate the disparity map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_block_mathcing = triangulate_disparity(\n",
    "    disparity=disparity_map,\n",
    "    lens_model_0=stereo_data.lens_model_0,\n",
    "    lens_model_1=stereo_data.lens_model_1,\n",
    "    transformation_matrix=stereo_data.transformation_matrix,\n",
    ")\n",
    "if xyz_block_mathcing is not None:\n",
    "    simple_plot(data=xyz_block_mathcing[..., 2], title=\"Block Matching Depth Map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "if xyz_block_mathcing is not None:\n",
    "    open3d_visualize_point_cloud(xyz=xyz_block_mathcing, rgb=rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plane Sweeping\n",
    "\n",
    "In [workshop 7](./07_stereo_matching_fundamentals_continued.ipynb) we looked at how plane sweeping as an alternative way to do block matching. We can use the function `plane_sweeping` from the [`plane_sweeping`](../oaf_vision_3d/plane_sweeping.py) module to get the xyz values directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_plane_sweeping = plane_sweeping(\n",
    "    image=stereo_data.image_0,\n",
    "    lens_model=stereo_data.lens_model_0,\n",
    "    secondary_images=[stereo_data.image_1],\n",
    "    secondary_lens_models=[stereo_data.lens_model_1],\n",
    "    secondary_transformation_matrices=[stereo_data.transformation_matrix],\n",
    "    depth_range=np.array([5000, 20000], dtype=np.float32),\n",
    "    step_size=150.0,\n",
    "    block_size=np.array([11, 11], dtype=np.int32),\n",
    ")\n",
    "if xyz_plane_sweeping is not None:\n",
    "    simple_plot(data=xyz_plane_sweeping[..., 2], title=\"Plane Sweeping Depth Map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "if xyz_plane_sweeping is not None:\n",
    "    open3d_visualize_point_cloud(xyz=xyz_plane_sweeping, rgb=rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An added advantage of plane sweeping is that it does not limit us to a stereo camera setup, in fact, we can use any number of cameras to get the depth map. This uses the constrains given by the calibration of the cameras to match agains all images at the same time. We can show this of on the following dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "stereo_data_0 = StereoData.from_path(TestDataPaths.stereo_data_0_dir)\n",
    "stereo_data_1 = StereoData.from_path(TestDataPaths.stereo_data_1_dir)\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(12, 15))\n",
    "ax[0].imshow(stereo_data_1.image_1, cmap=\"gray\", vmin=0, vmax=1)\n",
    "ax[0].set_title(\"Image left\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].imshow(stereo_data_0.image_0, cmap=\"gray\", vmin=0, vmax=1)\n",
    "ax[1].set_title(\"Image main\")\n",
    "ax[1].axis(\"off\")\n",
    "ax[2].imshow(stereo_data_0.image_1, cmap=\"gray\", vmin=0, vmax=1)\n",
    "ax[2].set_title(\"Image right\")\n",
    "ax[2].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the same plane sweeping algorithm, but now giving both the left and right images as secondary images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_plane_sweeping_multiple = plane_sweeping(\n",
    "    image=stereo_data_0.image_0,\n",
    "    lens_model=stereo_data_0.lens_model_0,\n",
    "    secondary_images=[stereo_data_0.image_1, stereo_data_1.image_1],\n",
    "    secondary_lens_models=[stereo_data_0.lens_model_1, stereo_data_1.lens_model_1],\n",
    "    secondary_transformation_matrices=[\n",
    "        stereo_data_0.transformation_matrix,\n",
    "        stereo_data_1.transformation_matrix,\n",
    "    ],\n",
    "    depth_range=np.array([135.0, 142.0], dtype=np.float32),\n",
    "    step_size=0.5,\n",
    "    block_size=np.array([11, 11], dtype=np.int32),\n",
    ")\n",
    "if xyz_plane_sweeping_multiple is not None:\n",
    "    simple_plot(\n",
    "        data=xyz_plane_sweeping_multiple[..., 2],\n",
    "        title=\"Multiple Image Plane Sweeping Depth Map\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "if xyz_plane_sweeping_multiple is not None:\n",
    "    open3d_visualize_point_cloud(\n",
    "        xyz=xyz_plane_sweeping_multiple, rgb=stereo_data_0.image_0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this workshop we have combined all the tools we have made in this series to make a full 3D stereo matching pipeline. The results are not perfect, but they are a good starting point for further development. Even though we can cleary see the limitations with the block matching algorithm, the undelying math is close to same for most baseline based triangulation methods. Meaning the knowledge we have gained in this series can be used to understand and develop more advanced 3D vision algorithms.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "This is the final workshop in the series. I hope you have learned a lot and that you have enjoyed the journey. If you have any questions or feedback, feel free to reach out to me. I would love to hear from you.\n",
    "\n",
    "Good luck with your future projects and I hope to see you again in future workshops."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
